////
START GENERATED ATTRIBUTES
WARNING: This content is generated by running npm --prefix .build run generate:attributes
////


:community:
:imagesdir: ./images
:product-version: 1
:product-long: Application Services
:product: App Services
// Placeholder URL, when we get a HOST UI for the service we can put it here properly
:service-url: https://cloud.redhat.com/beta/application-services/streams/
:property-file-name: app-services.properties

// Other upstream project names
:samples-git-repo: https://github.com/redhat-developer/app-services-guides

//URL components for cross refs
:base-url: https://github.com/redhat-developer/app-services-guides/blob/main/
:base-url-cli: https://github.com/redhat-developer/app-services-cli/tree/main/docs/
:getting-started-url: getting-started/README.adoc
:kafka-bin-scripts-url: kafka-bin-scripts/README.adoc
:kafkacat-url: kafkacat/README.adoc
:quarkus-url: quarkus/README.adoc
:rhoas-cli-url: rhoas-cli/README.adoc
:rhoas-cli-ref-url: commands
:topic-config-url: topic-configuration/README.adoc

////
END GENERATED ATTRIBUTES
////

[id="chap-binding-openshift-applications-to-{product-long}"]
= Binding OpenShift applications to {product-long}
:context: binding-openshift-to-app-services

[IMPORTANT]
====
{product-long} is currently available for Development Preview. Development Preview releases provide early access to a limited set of features that might not be fully tested and that might change in the final GA version. Users should not use Development Preview software in production or for business-critical workloads. Limited documentation is available for Development Preview releases and is typically focused on fundamental user goals.
====

[role="_abstract"]
As a developer of applications and services, there might be cases where you need to connect applications deployed on a Kubernetes platform such as Red Hat OpenShift to Kafka instances created in {product-long}.

For example, suppose that you have two applications deployed to an OpenShift cluster:

* One application that publishes price updates for a variety of stocks
* A second application that consumes the price updates for publication on a web page

In addition, you have a Kafka instance in {product}. Each time there is a price update, you want to use the Kafka instance to forward the update as an event to the consuming application.

To achieve this behavior, you need a way to connect the applications in OpenShift to your Kafka instance in {product}. Connecting a Kubernetes application to a backing service such as {product} is called __service binding__.

This guide describes how to use the OpenShift Application Services (RHOAS) Operator to perform service binding for {product}. The Kubernetes platform used throughout this guide is Red Hat OpenShift.

[id="con-about-service-binding-using-rhoas-operator_{context}"]
== About service binding using the RHOAS Operator

Connecting a Kubernetes application to a backing service such as {product-long} is called __service binding__. To perform service binding for {product}, you use the OpenShift Application Services (RHOAS) Operator.

The RHOAS Operator enables you to expose Kafka instances created in {product} to applications in separate OpenShift clusters. When you install the RHOAS Operator, you can use the RHOAS CLI to inject connection credentials for a specified Kafka instance to an application running in a given namespace in your OpenShift cluster. With connection between your application and Kafka instance established, you can then work directly with the Kafka instance using standard OpenShift features and APIs.

When you use the RHOAS CLI to bind a Kafka instance with an application, the RHOAS Operator injects connection credentials as files into the Pod for your application. By default, the RHOAS Operator creates the following directory and file structure in the application Pod:

[source, subs="+quotes"]
----
/bindings/__<my-kafka-instance>__
├── bootstrapServers
├── password
├── provider
├── saslMechanism
├── securityProtocol
├── type
└── user
----

Each file that the RHOAS Operator injects into the application Pod contains a single connection credential, included in plain text. The connection credentials that correspond to these files are described below.

bootstrapServers:: Bootstrap server endpoint for the Kafka instance
password:: Password for connection to the Kafka instance
provider:: Cloud provider for the Kafka instance
saslMechanism:: __Simple Authentication and Security Layer__ (SASL) mechanism used by the Kafka instance for client authentication
securityProtocol:: Protocol used by the Kafka instance to secure client connections
type:: Metadata that identifies the Red Hat OpenShift Application Services (RHOAS) service. For a Kafka instance in {product-long}, this is set to a value of `kafka`.
user:: User name for connection to the Kafka instance

[id="proc-installing-rhoas-operator_{context}"]
== Installing the RHOAS Operator on OpenShift

[role="_abstract"]
Before you can bind Kafka instances in {product-long} to applications in OpenShift, you need to install the OpenShift Application Services (RHOAS) Operator. The following procedure shows how to use the OperatorHub interface in the OpenShift web console to install the RHOAS Operator.

.Prerequisites
* You have cluster administrator access for your OpenShift cluster.

.Procedure
. Log in to the OpenShift web console as a cluster administrator.
. Click the perspective switcher in the top-left corner. Switch to the *Administrator* perspective.
. In the left menu, click *Operators* > *OperatorHub*.
. In the *Filter by keyword* field, enter `RHOAS`.
. Select the *OpenShift Application Services (RHOAS)* Operator.
. If you see a dialog box entitled *Show community Operator*, review the included information. When you have finished, click *Continue*.
+
An information sidebar for the RHOAS Operator opens.

. In the sidebar, review the information about the RHOAS Operator and click *Install*.
. On the *Install Operator* page:
.. For the *Installation mode* option, ensure that `All namespaces on the cluster` is selected.
.. For the *Update channel* and *Update approval* options, keep the default values.
.. Click *Install*.
. When the installation process finishes, click *View Operator* to see the RHOAS Operator details. Alternatively, in the left menu, click *Operators* > *Installed Operators* and then click the RHOAS Operator.
+
Observe that the RHOAS Operator is installed in the `openshift-operators` namespace by default.

[id="proc-binding-openshift-to-{product-long}-using-cli_{context}"]
== Tutorial: Binding an OpenShift application to {product-long} using the RHOAS CLI

[role="_abstract"]
When the OpenShift Application Services (RHOAS) Operator is installed in your OpenShift cluster, you can use the RHOAS CLI to interact directly with the cluster. For example, you can use the CLI to connect an application running in the cluster to a Kafka instance in {product-long}. Establishing a connection between an OpenShift application and a backing service such as {product} is called _service binding_.

The following tutorial shows how to use the RHOAS CLI to perform service binding. In the tutorial, you create an example Quarkus application and connect this to a Kafka instance. link:https://quarkus.io/[Quarkus^] is a Kubernetes-native Java framework that is optimized for serverless, cloud, and Kubernetes environments.

IMPORTANT: Some steps in the tutorial require cluster administrator access for your OpenShift cluster.

=== Step 1: Verifying connection to your OpenShift cluster

[role="_abstract"]
In this step of the tutorial, you verify that the installed RHOAS Operator is working by using the RHOAS CLI to connect to the OpenShift cluster and retrieve the cluster status.

.Prerequisites
* The RHOAS Operator is installed in your OpenShift cluster. See xref:proc-installing-operator_{context}[Installing the RHOAS Operator in your OpenShift cluster].
* You have cluster administrator access for your OpenShift cluster.
* You have installed the OpenShift CLI. For more information, see link:https://docs.openshift.com/container-platform/4.7/cli_reference/openshift_cli/getting-started-cli.html#installing-openshift-cli[Installing the OpenShift CLI].
ifndef::community[]
* You have installed the RHOAS CLI. For more information, see link:https://access.redhat.com/documentation/en-us/red_hat_openshift_streams_for_apache_kafka/1/guide/f520e427-cad2-40ce-823d-96234ccbc047#_8818f0d5-ae20-42c8-9622-a98e663ff1a8[Installing the RHOAS CLI].
endif::[]
ifdef::community[]
* You have installed the RHOAS CLI. For more information, see link:{base-url}{rhoas-cli-url}#proc-installing-rhoas_getting-started-rhoas[Installing the RHOAS CLI].
endif::[]

.Procedure
. Log in to your OpenShift cluster as a cluster administrator. For example:
+
[source,subs="+quotes"]
----
$ oc login -u system:admin -p __<password>__ --server=__<host:port>__
----

. Create a new project. For example:
+
[source, subs="+quotes"]
----
$ oc new-project rhoas-quarkus
----

. Log in to the RHOAS CLI.
+
[source]
----
$ rhoas login
----

. Use the RHOAS CLI to connect to your OpenShift cluster and retrieve the cluster status.
+
[source]
----
$ rhoas cluster status
Namespace: rhoas-quarkus
RHOAS Operator: Installed
----
+
As shown in the output, the CLI indicates that the RHOAS Operator was successfully installed. The CLI uses the RHOAS Operator to retrieve the name of the current OpenShift project (namespace).

=== Step 2: Connecting a Kafka instance to your OpenShift cluster

[role="_abstract"]
When you have verified connection to your OpenShift cluster, you can connect a specific Kafka instance created in {product} to the current project in the cluster. In this step of the tutorial, you use the RHOAS CLI to connect a specified Kafka instance to a project in your cluster.

.Prerequisites
* You have completed *Step 1: Verifying connection to your OpenShift cluster*.
ifndef::community[]
* You have a Kafka instance in {product-long} that is in the *Ready* state. To learn how to create a Kafka instance, see link:https://access.redhat.com/documentation/en-us/red_hat_openshift_streams_for_apache_kafka/1/guide/f351c4bd-9840-42ef-bcf2-b0c9be4ee30a[Getting started with Streams for Apache Kafka].
endif::[]
ifdef::community[]
* You have a Kafka instance in {product-long} that is in the *Ready* state. To learn how to create a Kafka instance, see link:{base-url}{getting-started-url}[Getting started with {product-long}].
endif::[]
* You have an API token to connect to your Kafka instance. To get a token, see the link:https://cloud.redhat.com/openshift/token[OpenShift Cluster Manager API Token] page.
* You have privileges to create a new project in your OpenShift cluster.

.Procedure

. If you are not already logged in to your OpenShift cluster, log in as a user (such as a cluster administrator) that has privileges to create a new project in the cluster. For example:
+
[source, subs="+quotes"]
----
$ oc login -u system:admin -p __<password>__ --server=__<host:port>__
----

. Ensure that the current OpenShift project is the one created in the previous step of this tutorial. For example:
+
[source]
----
$ oc project rhoas-quarkus
----

. Connect a Kafka instance in {product} to the current project in your OpenShift cluster.
+
[source]
----
$ rhoas cluster connect --ignore-context
----
+
You are prompted to specify the Kafka instance that you want to connect to OpenShift.

. Type the name of the Kafka instance that you want to connect to OpenShift. Press *Enter*.
+
You should see output like the following:
+
[source]
----
Connection Details:

Apache Kafka instance:  my-kafka-instance
Kubernetes Namespace:   rhoas-quarkus
Service Account Secret: rh-cloud-services-service-account
----

. Verify the connection details shown by the CLI. When you are ready to continue, type `y`. Then, press *Enter*.
+
You are prompted to provide an access token. The RHOAS Operator requires this token to make a connection to your Kafka instance.

. In your web browser, open the link:https://cloud.redhat.com/openshift/token[OpenShift Cluster Manager API Token] page. Copy the access token shown.

. In your terminal window, right-click and select *Paste*. Press *Enter*.
+
the RHOAS Operator uses the token to create a `KafkaConnection` resource on your OpenShift cluster. When this process is complete, you should see lines like the following:
+
[source]
----
KafkaConnection resource "my-kafka-instance" has been created
Waiting for status from KafkaConnection resource.
Created KafkaConnection can be injected into your application.
...
KafkaConnection successfully installed on your cluster.
----

. Verify that the RHOAS Operator successfully created the connection.
+
[source]
----
$ oc get KafkaConnection

NAME   		         AGE
my-kafka-instance        2m35s
----
+
As shown in the output, the RHOAS Operator creates a `KafkaConnection` resource that matches the name of your Kafka instance.

=== Step 3: Deploying an example application in OpenShift

[role="_abstract"]
In this step of the tutorial, you deploy an example Quarkus application in the OpenShift project that you created earlier in the tutorial. link:https://quarkus.io/[Quarkus^] is a Kubernetes-native Java framework that is optimized for serverless, cloud, and Kubernetes environments.

The Quarkus application generates random numbers between 0 and 100 and produces those numbers to a Kafka topic. Another part of the application consumes the numbers from the Kafka topic. Finally, the application uses __Server-Sent Events__ (SSE) to expose the numbers as a REST UI. A web page in the application displays the exposed numbers.

.Prerequisites
* You have completed the previous steps in this tutorial:
** *Step 1: Verifying connection to your OpenShift cluster*
** *Step 2: Connecting a Kafka instance to your OpenShift cluster*
* You have privileges to deploy applications in the OpenShift project created earlier in this tutorial.

.Procedure

. If you are not already logged in to your OpenShift cluster, log in as a user that has privileges to deploy applications in the OpenShift project created earlier in this tutorial.
+
[source,subs="+quotes"]
----
$ oc login -u __<user>__ -p __<password>__ --server=__<host:port>__
----

. Ensure that the current OpenShift project is the one created earlier in this tutorial. For example:
+
[source]
----
$ oc project rhoas-quarkus
----

. To deploy the Quarkus application, apply an example application template provided by Red Hat.
+
[source,options="nowrap"]
----
$ oc apply -f https://raw.githubusercontent.com/redhat-developer/app-services-guides/main/code-examples/quarkus-kafka-quickstart/.kubernetes/kubernetes.yml

service/rhoas-quarkus-kafka created
deployment.apps/rhoas-quarkus-kafka created
route.route.openshift.io/rhoas-quarkus-kafka created
----
+
As shown in the output, deploying the application automatically creates a Service and Route for access to the application.

. Get the URL of the Route created for the application.
+
[source,options="nowrap"]
----
$ oc get route

NAME                   HOST/PORT
rhoas-quarkus-kafka    rhoas-quarkus-kafka-jbyrne-dev.apps.sandbox-m2.ll9k.p1.openshiftapps.com
----

. In your terminal, highlight the URL shown under *HOST/PORT*. Right-click in the terminal window and  select *Copy*.

. In your web browser, paste the URL for the Route.
+
A web page for the Quarkus application opens.

. In your web browser, append `prices.html` to the URL.
+
A new web page, entitled *Last price*, opens.  Because you have not yet connected the Quarkus application to your Kafka instance, the price value appears as `N/A`.

=== Step 4: Creating a topic in your Kafka instance

[role="_abstract"]
In the previous step of this tutorial, you created an example OpenShift application. The application is a Quarkus application that requires a Kafka topic called `prices`. In this step, you create the `prices` topic in your Kafka instance so that the Quarkus application can interact with it.

.Prerequisites
* You have completed the previous steps in this tutorial:
** *Step 1: Verifying connection to your OpenShift cluster*
** *Step 2: Connecting a Kafka instance to your OpenShift cluster*
** *Step 3: Deploying an example application in OpenShift*
ifndef::community[]
* You have a Kafka instance in {product} that is in the *Ready* state. To learn how to create a Kafka instance, see link:https://access.redhat.com/documentation/en-us/red_hat_openshift_streams_for_apache_kafka/1/guide/f351c4bd-9840-42ef-bcf2-b0c9be4ee30a[Getting started with Streams for Apache Kafka].
endif::[]
ifdef::community[]
* You have a Kafka instance in {product} that is in the *Ready* state. To learn how to create a Kafka instance, see link:{base-url}{getting-started-url}[Getting started with {product-long}].
endif::[]

.Procedure
. On the *Kafka instances* page of the web console, click the name of the Kafka instance that you want to add a topic to.

. Click *Create topic* and follow the guided steps to define the topic details. Click *Next* to complete each step and click *Finish* to complete the setup.
+
.Guided steps to define topic details
image::sak-create-topic.png[Image of wizard to create a topic]

*Topic name*:: Enter `prices` as the topic name.
*Partitions*:: Set the number of partitions for this topic. For this tutorial, set a value of `1`. Partitions are distinct lists of messages within a topic and enable parts of a topic to be distributed over multiple brokers in the cluster. A topic can contain one or more partitions, enabling producer and consumer loads to be scaled.
+
NOTE: You can increase the number of partitions later, but you cannot decrease them.
+
*Message retention*:: Set the message retention time to the relevant value and increment. For this tutorial, set a value of `7 days`. Message retention time is the amount of time that messages are retained in a topic before they are deleted or compacted, depending on the cleanup policy.
*Replicas*:: For this release of {product}, the replicas are preconfigured. The number of partition replicas for the topic is set to `3` and the minimum number of follower replicas that must be in sync with a partition leader is set to `2`. Replicas are copies of partitions in a topic. Partition replicas are distributed over multiple brokers in the cluster to ensure topic availability if a broker fails. When a follower replica is in sync with a partition leader, the follower replica can become the new partition leader if needed.
+
After you complete the topic setup, the new Kafka topic is listed in the topics table.

=== Step 5: Binding your Kafka instance to your OpenShift application

In this step of the tutorial, you use the RHOAS CLI to bind your Kafka instance to your OpenShift application. When you perform this binding, the RHOAS CLI injects connection credentials as files into the Pod for the application. In the case of a Quarkus application, Quarkus automatically detects the credentials and configures the application to use them.

.Prerequisites
* You have completed the previous steps in this tutorial:
** *Step 1: Verifying connection to your OpenShift cluster*
** *Step 2: Connecting a Kafka instance to your OpenShift cluster*
** *Step 3: Deploying an example application in OpenShift*
** *Step 4: Creating a topic in your Kafka instance*
* You should understand how the RHOAS CLI injects connection credentials as files into a client application Pod. To learn more, see xref:con-about-service-binding-using-rhoas-operator_{context}[].

.Procedure
. If you are not already logged in to your OpenShift cluster, log in as a user that has privileges to deploy applications in the OpenShift project created earlier in this tutorial.
+
[source, subs="+quotes"]
----
$ oc login -u __<user>__ -p __<password>__ --server=__<host:port>__
----
. Ensure that the current OpenShift project is the one created earlier in this tutorial. For example:
+
[source]
----
$ oc project rhoas-quarkus
----

. Use the RHOAS CLI to bind your Kafka instance to your OpenShift project.
+
[source]
----
$ rhoas cluster bind
----
+
You are prompted to specify the Kafka instance that you want to connect to OpenShift.

. Type the name of the Kafka instance that you want to connect to OpenShift. Press *Enter*.
. Type `y` to confirm that you want to continue. Press *Enter*.
+
When binding is complete, you should see output like the following:
+
[source]
----
Binding my-kafka-instance with rhoas-quarkus-kafka app succeeded
----
+
The preceding output shows that the RHOAS CLI has successfully bound a Kafka instance called `my-kafka-instance` to the example Quarkus application (called `rhoas-quarkus-kafka`) in OpenShift. As part of this process, the RHOAS Operator injects connection credentials for the Kafka instance into the Pod for the Quarkus application. Quarkus automatically detects the credentials and uses them to interact with the Kafka instance.
+
When service binding is complete, the Quarkus application starts to use the `prices` Kafka topic that you created earlier in the tutorial. One part of the Quarkus application publishes price updates to this topic, while another part of the application consumes the updates.

. To verify that the Quarkus application is using the Kafka topic, reload the *Last price* web page that you opened in step 3 of this tutorial.
+
On the web page, observe that the Quarkus application now continuously updates the price value.
