////
START GENERATED ATTRIBUTES
WARNING: This content is generated by running npm --prefix .build run generate:attributes
////

//OpenShift Application Services
:org-name: Application Services
:product-long-rhoas: OpenShift Application Services
:community:
:imagesdir: ./images
:property-file-name: app-services.properties
:samples-git-repo: https://github.com/redhat-developer/app-services-guides
:base-url: https://github.com/redhat-developer/app-services-guides/tree/main/docs/

//OpenShift Application Services CLI
:rhoas-cli-base-url: https://github.com/redhat-developer/app-services-cli/tree/main/docs/
:rhoas-cli-ref-url: commands
:rhoas-cli-installation-url: rhoas/rhoas-cli-installation/README.adoc

//OpenShift Streams for Apache Kafka
:product-long-kafka: OpenShift Streams for Apache Kafka
:product-kafka: Streams for Apache Kafka
:product-version-kafka: 1
:service-url-kafka: https://console.redhat.com/application-services/streams/
:getting-started-url-kafka: kafka/getting-started-kafka/README.adoc
:kafka-bin-scripts-url-kafka: kafka/kafka-bin-scripts-kafka/README.adoc
:kafkacat-url-kafka: kafka/kcat-kafka/README.adoc
:quarkus-url-kafka: kafka/quarkus-kafka/README.adoc
:nodejs-url-kafka: kafka/nodejs-kafka/README.adoc
:rhoas-cli-getting-started-url-kafka: kafka/rhoas-cli-getting-started-kafka/README.adoc
:topic-config-url-kafka: kafka/topic-configuration-kafka/README.adoc
:consumer-config-url-kafka: kafka/consumer-configuration-kafka/README.adoc
:access-mgmt-url-kafka: kafka/access-mgmt-kafka/README.adoc
:metrics-monitoring-url-kafka: kafka/metrics-monitoring-kafka/README.adoc
:service-binding-url-kafka: kafka/service-binding-kafka/README.adoc

//OpenShift Service Registry
:product-long-registry: OpenShift Service Registry
:product-registry: Service Registry
:registry: Service Registry
:product-version-registry: 1
:service-url-registry: https://console.redhat.com/application-services/service-registry/
:getting-started-url-registry: registry/getting-started-registry/README.adoc
:quarkus-url-registry: registry/quarkus-registry/README.adoc
:rhoas-cli-getting-started-url-registry: registry/rhoas-cli-getting-started-registry/README.adoc
:access-mgmt-url-registry: registry/access-mgmt-registry/README.adoc

////
END GENERATED ATTRIBUTES
////

[id="chap-browsing-messages"]
= Browsing messages in the {product-long-kafka} web console
ifdef::context[:parent-context: {context}]
:context: browsing-messages

// Purpose statement for the assembly
[role="_abstract"]

As a developer or administrator, you can use the {product-long-kafka} web console to view and inspect messages for a Kafka topic. You might use this functionality, for example, to verify that a client is producing messages to the expected topic partition, that your topic is storing messages correctly, or that messages have the expected content.

When you select a topic in the console, you can use the *Messages* tab to view a list of messages for that topic. You can filter the list of messages in the following ways:

* Specify a partition and see the last ten message sent to the partition.
* Specify a partition and offset. See the last ten messages sent to the partition from that offset.
* Specify a partition and a timestamp (that is, date and time) value. See the last ten messages sent to the partition from that date and time.
* Specify a partition and a Unix epoch timestamp value. See the last ten messages sent to the partition from that epoch timestamp value.

//Additional line break to resolve mod docs generation error.

[id="proc-browsing-messages-for-a-topic_{context}"]
== Browsing messages for a topic

The following procedure shows how to filter and inspect a list of messages for a topic in the {product-kafka} web console.

.Prerequisites

* You have a Kafka instance with a topic that contains some messages. To learn how to create your _first_ Kafka instance and topic and then send messages to the topic that will appear on the *Messages* page, see the following guides:
+
** {base-url}{getting-started-url-kafka}[Getting started with {product-long-kafka}^]
** {base-url}{kafka-bin-scripts-url-kafka}[Configuring and connecting Kafka scripts with {product-long-kafka}^]

.Procedure

. In the {product-kafka} web console, click *Kafka Instances* in the left navigation menu.
. On the *Kafka Instances* page, click a Kafka instance.
. In your Kafka instance, click the *Topics* tab.
. In the topics table, click a Kafka topic that you want to inspect.
. In your topic, click the *Messages* tab.
+
By default, the *Messages* page displays a table that shows the last ten messages in *partition 0* of your topic. You can change this partition value, as described later in the procedure.
+
The table includes columns for the following topic and message properties:
+
--
* Partition
* Offset
* Timestamp (date and time)
* Key
* Value
* Headers
--

. To see complete data for a message, click *Show more* in the *Value* or *Headers* column.
+
A side drawer opens. Additional information shown in the side drawer is the full message value and header, the message size, the epoch timestamp value, and the timestamp type (that is, `Create time` or `Log append time`).
+
[NOTE]
--
If you're using a schema in {product-long-registry} with your topic, the *Messages* page does *not* deserialize messages that a producer application serialized to conform to that schema. To view such messages, you must configure a consumer application to use a Kafka deserializer. For more information, see https://access.redhat.com/documentation/en-us/red_hat_integration/2021.q3/html-single/service_registry_user_guide/index#configuring-kafka-client-serdes[Configuring Kafka serializers/deserializers in Java clients^].

Similarly, if a message is encoded (for example, in a format such as UTF-8 or Base64), the *Messages* page does not decode the message.
--

. To copy the full message value, click the copy icon in the side drawer.

. To see messages for a different topic partition, select a new value in the *Select partition* drop-down menu.
+
NOTE: If you have many partitions, you can filter the list shown in the drop-down menu by typing a value in the field.

. To further refine the list of messages in the table, use the filter controls at the top of the *Messages* page.
+
--
.. To filter messages by topic partition and offset, perform the following actions:
... In the *Select partition* field, select a topic partition.
... In the drop-down menu that shows a default value of `Offset`, keep this default value.
... In the *Select offset* field, type an offset value.
... To apply your filter settings, click the search (magnifying glass) icon.

.. To filter messages by topic partition and date and time, perform the following actions:
... In the *Select partition* field, select a topic partition.
... In the drop-down menu that shows a default value of `Offset`, change the value to `Timestamp`.
+
Additional selection tools appear.
... Use the additional selection tools to set date and time values. Alternatively, type a date and time value in the format shown in the field.
... To apply your filter settings, click the search (magnifying glass) icon.

.. To filter messages by topic partition and epcoh timestamp, perform the following actions:
... In the *Select partition* field, select a topic partition.
... In the drop-down menu that shows a default value of `Offset`, change the value to `Epoch timestamp`.
... In the *Select epoch timestamp* field, type or paste an epoch timestamp value.
+
NOTE: You can easily convert a human-readable date and time to an epoch value using a https://www.epochconverter.com/[timestamp conversion tool^].
... To apply your filter settings, click the search (magnifying glass) icon.

--
+
Based on your filter settings, the *Messages* page automatically reloads the list of messsages in the table.

. To clear your existing offset, timestamp, or epoch timestamp selections and revert to seeing the last ten messages in the selected partition, select `Latest messages` in the drop-down menu that has a default value of `Offset`.

ifdef::parent-context[:context: {parent-context}]
ifndef::parent-context[:!context:]
